#!/usr/bin/env python3
"""
ç¤¾äº¤å†…å®¹GEOä¼˜åŒ–å·¥å…·
ä¸“ä¸ºTikTokã€Instagramã€YouTubeç­‰ç¤¾äº¤å¹³å°çš„AIæ¨èå¼•æ“ä¼˜åŒ–å†…å®¹
"""

import json
import re
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Union
import numpy as np
from dataclasses import dataclass
from enum import Enum
import cv2
import librosa
import nltk
from transformers import pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import hashlib


class SocialPlatform(Enum):
    """ç¤¾äº¤å¹³å°æšä¸¾"""
    TIKTOK = "tiktok"
    INSTAGRAM = "instagram"
    YOUTUBE = "youtube"
    FACEBOOK = "facebook"
    TWITTER = "twitter"
    PINTEREST = "pinterest"


class ContentType(Enum):
    """å†…å®¹ç±»å‹æšä¸¾"""
    VIDEO_SHORT = "video_short"  # çŸ­è§†é¢‘ï¼ˆ<60sï¼‰
    VIDEO_LONG = "video_long"    # é•¿è§†é¢‘ï¼ˆ>60sï¼‰
    IMAGE_POST = "image_post"    # å›¾ç‰‡å¸–å­
    CAROUSEL = "carousel"        # è½®æ’­å›¾
    STORY = "story"             # å¿«æ‹/æ•…äº‹
    REEL = "reel"               # Reels
    LIVE = "live"               # ç›´æ’­


@dataclass
class SocialOptimizationResult:
    """ç¤¾äº¤å†…å®¹ä¼˜åŒ–ç»“æœ"""
    platform: SocialPlatform
    content_type: ContentType
    original_content: Dict
    optimized_content: Dict
    ai_recommendation_score: float  # AIæ¨èæ¦‚ç‡å¾—åˆ†
    first_3_seconds_score: float    # é¦–3ç§’ç•™å­˜å¾—åˆ†
    completion_rate_prediction: float  # é¢„æµ‹å®Œæ’­ç‡
    engagement_prediction: float     # é¢„æµ‹äº’åŠ¨ç‡
    viral_potential_score: float    # ç—…æ¯’ä¼ æ’­æ½œåŠ›åˆ†æ•°
    optimization_suggestions: List[Dict]
    metadata_enhancements: Dict
    hashtag_recommendations: List[str]
    timing_recommendations: Dict


class VideoAnalyzer:
    """è§†é¢‘å†…å®¹åˆ†æå™¨"""
    
    def __init__(self):
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        self.emotion_analyzer = pipeline("image-classification", model="dima806/facial_emotions_image_detection")
        
    def analyze_first_3_seconds(self, video_path: str) -> Dict[str, float]:
        """åˆ†æè§†é¢‘å‰3ç§’çš„å…³é”®æŒ‡æ ‡"""
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        metrics = {
            'motion_intensity': 0.0,
            'visual_complexity': 0.0,
            'face_presence': 0.0,
            'emotion_intensity': 0.0,
            'scene_changes': 0,
            'hook_strength': 0.0
        }
        
        frames_to_analyze = int(fps * 3)  # å‰3ç§’çš„å¸§æ•°
        prev_frame = None
        motion_scores = []
        complexity_scores = []
        
        for i in range(frames_to_analyze):
            ret, frame = cap.read()
            if not ret:
                break
                
            # è¿åŠ¨å¼ºåº¦åˆ†æ
            if prev_frame is not None:
                motion = cv2.absdiff(prev_frame, frame)
                motion_score = np.mean(motion)
                motion_scores.append(motion_score)
            
            # è§†è§‰å¤æ‚åº¦åˆ†æ
            edges = cv2.Canny(frame, 100, 200)
            complexity = np.sum(edges > 0) / edges.size
            complexity_scores.append(complexity)
            
            # äººè„¸æ£€æµ‹
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)
            
            if len(faces) > 0:
                metrics['face_presence'] += 1 / frames_to_analyze
                
                # æƒ…ç»ªåˆ†æï¼ˆæ¯10å¸§åˆ†æä¸€æ¬¡ä»¥æé«˜æ€§èƒ½ï¼‰
                if i % 10 == 0:
                    try:
                        # è£å‰ªäººè„¸åŒºåŸŸ
                        x, y, w, h = faces[0]
                        face_img = frame[y:y+h, x:x+w]
                        emotions = self.emotion_analyzer(face_img)
                        if emotions:
                            # è®¡ç®—æƒ…ç»ªå¼ºåº¦
                            emotion_score = max([e['score'] for e in emotions])
                            metrics['emotion_intensity'] = max(metrics['emotion_intensity'], emotion_score)
                    except:
                        pass
            
            # åœºæ™¯å˜åŒ–æ£€æµ‹
            if prev_frame is not None and i % 5 == 0:
                hist_diff = self._compare_histograms(prev_frame, frame)
                if hist_diff > 0.5:
                    metrics['scene_changes'] += 1
            
            prev_frame = frame
        
        cap.release()
        
        # è®¡ç®—ç»¼åˆæŒ‡æ ‡
        metrics['motion_intensity'] = np.mean(motion_scores) if motion_scores else 0
        metrics['visual_complexity'] = np.mean(complexity_scores) if complexity_scores else 0
        
        # è®¡ç®—é’©å­å¼ºåº¦ï¼ˆç»¼åˆè¯„åˆ†ï¼‰
        metrics['hook_strength'] = self._calculate_hook_strength(metrics)
        
        return metrics
    
    def _compare_histograms(self, frame1, frame2):
        """æ¯”è¾ƒä¸¤å¸§çš„ç›´æ–¹å›¾å·®å¼‚"""
        hist1 = cv2.calcHist([frame1], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])
        hist2 = cv2.calcHist([frame2], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])
        
        hist1 = cv2.normalize(hist1, hist1).flatten()
        hist2 = cv2.normalize(hist2, hist2).flatten()
        
        return cv2.compareHist(hist1, hist2, cv2.HISTCMP_CHISQR_ALT)
    
    def _calculate_hook_strength(self, metrics: Dict) -> float:
        """è®¡ç®—è§†é¢‘é’©å­å¼ºåº¦"""
        weights = {
            'motion_intensity': 0.25,
            'visual_complexity': 0.20,
            'face_presence': 0.30,
            'emotion_intensity': 0.15,
            'scene_changes': 0.10
        }
        
        # å½’ä¸€åŒ–åœºæ™¯å˜åŒ–æ•°ï¼ˆç†æƒ³å€¼ä¸º1-2æ¬¡ï¼‰
        scene_change_score = min(metrics['scene_changes'] / 2, 1.0)
        
        hook_score = (
            metrics['motion_intensity'] * weights['motion_intensity'] +
            metrics['visual_complexity'] * weights['visual_complexity'] +
            metrics['face_presence'] * weights['face_presence'] +
            metrics['emotion_intensity'] * weights['emotion_intensity'] +
            scene_change_score * weights['scene_changes']
        )
        
        return min(hook_score, 1.0)


class AudioAnalyzer:
    """éŸ³é¢‘å†…å®¹åˆ†æå™¨"""
    
    def __init__(self):
        self.sample_rate = 22050
        
    def analyze_audio_hooks(self, audio_path: str) -> Dict[str, float]:
        """åˆ†æéŸ³é¢‘é’©å­å…ƒç´ """
        # åŠ è½½éŸ³é¢‘
        y, sr = librosa.load(audio_path, sr=self.sample_rate)
        
        metrics = {
            'beat_strength': self._analyze_beat_strength(y, sr),
            'onset_density': self._analyze_onset_density(y, sr),
            'energy_variation': self._analyze_energy_variation(y, sr),
            'trending_audio_match': self._check_trending_audio_match(y, sr),
            'vocal_clarity': self._analyze_vocal_clarity(y, sr)
        }
        
        return metrics
    
    def _analyze_beat_strength(self, y, sr):
        """åˆ†æèŠ‚å¥å¼ºåº¦"""
        tempo, beats = librosa.beat.beat_track(y=y, sr=sr)
        beat_strength = len(beats) / (len(y) / sr)  # æ¯ç§’èŠ‚æ‹æ•°
        return min(beat_strength / 4, 1.0)  # å½’ä¸€åŒ–åˆ°0-1
    
    def _analyze_onset_density(self, y, sr):
        """åˆ†æéŸ³é¢‘èµ·å§‹å¯†åº¦"""
        onset_frames = librosa.onset.onset_detect(y=y, sr=sr)
        onset_density = len(onset_frames) / (len(y) / sr)
        return min(onset_density / 10, 1.0)
    
    def _analyze_energy_variation(self, y, sr):
        """åˆ†æèƒ½é‡å˜åŒ–"""
        rms = librosa.feature.rms(y=y)[0]
        variation = np.std(rms) / (np.mean(rms) + 1e-6)
        return min(variation, 1.0)
    
    def _check_trending_audio_match(self, y, sr):
        """æ£€æŸ¥æ˜¯å¦åŒ¹é…æµè¡ŒéŸ³é¢‘ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        # å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥ä¸è¶‹åŠ¿éŸ³é¢‘æ•°æ®åº“è¿›è¡ŒåŒ¹é…
        # è¿™é‡Œè¿”å›æ¨¡æ‹Ÿå€¼
        return 0.7
    
    def _analyze_vocal_clarity(self, y, sr):
        """åˆ†æäººå£°æ¸…æ™°åº¦"""
        # ä½¿ç”¨é¢‘è°±è´¨å¿ƒä½œä¸ºç®€åŒ–æŒ‡æ ‡
        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
        # äººå£°é€šå¸¸åœ¨1-4kHzèŒƒå›´
        vocal_range_ratio = np.sum((spectral_centroids > 1000) & (spectral_centroids < 4000)) / len(spectral_centroids)
        return vocal_range_ratio


class TextOptimizer:
    """æ–‡æœ¬å†…å®¹ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.sentiment_analyzer = pipeline("sentiment-analysis")
        self.trending_keywords = self._load_trending_keywords()
        
    def optimize_caption(self, caption: str, platform: SocialPlatform) -> Dict:
        """ä¼˜åŒ–ç¤¾äº¤åª’ä½“æ ‡é¢˜æ–‡æ¡ˆ"""
        optimized = {
            'original': caption,
            'optimized': caption,
            'improvements': []
        }
        
        # 1. é•¿åº¦ä¼˜åŒ–
        length_result = self._optimize_length(caption, platform)
        if length_result['changed']:
            optimized['optimized'] = length_result['text']
            optimized['improvements'].append(length_result['improvement'])
        
        # 2. è¡¨æƒ…ç¬¦å·ä¼˜åŒ–
        emoji_result = self._optimize_emojis(optimized['optimized'], platform)
        if emoji_result['changed']:
            optimized['optimized'] = emoji_result['text']
            optimized['improvements'].append(emoji_result['improvement'])
        
        # 3. CTAä¼˜åŒ–
        cta_result = self._optimize_cta(optimized['optimized'], platform)
        if cta_result['changed']:
            optimized['optimized'] = cta_result['text']
            optimized['improvements'].append(cta_result['improvement'])
        
        # 4. è¶‹åŠ¿å…³é”®è¯èå…¥
        keyword_result = self._integrate_trending_keywords(optimized['optimized'])
        if keyword_result['changed']:
            optimized['optimized'] = keyword_result['text']
            optimized['improvements'].append(keyword_result['improvement'])
        
        # 5. æƒ…æ„Ÿåˆ†æ
        optimized['sentiment'] = self._analyze_sentiment(optimized['optimized'])
        
        return optimized
    
    def _optimize_length(self, text: str, platform: SocialPlatform) -> Dict:
        """ä¼˜åŒ–æ–‡æœ¬é•¿åº¦"""
        optimal_lengths = {
            SocialPlatform.TIKTOK: (80, 150),
            SocialPlatform.INSTAGRAM: (125, 150),
            SocialPlatform.YOUTUBE: (70, 100),
            SocialPlatform.TWITTER: (100, 280)
        }
        
        min_len, max_len = optimal_lengths.get(platform, (80, 150))
        current_len = len(text)
        
        if current_len < min_len:
            # æ‰©å±•æ–‡æœ¬
            return {
                'changed': True,
                'text': text + " ğŸ¯ Don't miss out!",
                'improvement': f"Extended caption from {current_len} to optimal length"
            }
        elif current_len > max_len:
            # ç¼©çŸ­æ–‡æœ¬
            sentences = text.split('. ')
            shortened = '. '.join(sentences[:2]) + '...'
            return {
                'changed': True,
                'text': shortened,
                'improvement': f"Shortened caption from {current_len} to {len(shortened)} characters"
            }
        
        return {'changed': False, 'text': text}
    
    def _optimize_emojis(self, text: str, platform: SocialPlatform) -> Dict:
        """ä¼˜åŒ–è¡¨æƒ…ç¬¦å·ä½¿ç”¨"""
        emoji_pattern = re.compile(
            "["
            "\U0001F600-\U0001F64F"  # emoticons
            "\U0001F300-\U0001F5FF"  # symbols & pictographs
            "\U0001F680-\U0001F6FF"  # transport & map symbols
            "\U0001F1E0-\U0001F1FF"  # flags (iOS)
            "]+", 
            flags=re.UNICODE
        )
        
        current_emojis = len(emoji_pattern.findall(text))
        
        # å¹³å°æœ€ä½³å®è·µ
        optimal_emojis = {
            SocialPlatform.TIKTOK: (2, 4),
            SocialPlatform.INSTAGRAM: (3, 5),
            SocialPlatform.YOUTUBE: (1, 3)
        }
        
        min_emojis, max_emojis = optimal_emojis.get(platform, (2, 4))
        
        if current_emojis < min_emojis:
            # æ·»åŠ ç›¸å…³è¡¨æƒ…
            popular_emojis = ['ğŸ¯', 'âœ¨', 'ğŸ”¥', 'ğŸ’¡', 'ğŸš€']
            text_with_emojis = text
            for i in range(min_emojis - current_emojis):
                text_with_emojis += f" {popular_emojis[i % len(popular_emojis)]}"
            
            return {
                'changed': True,
                'text': text_with_emojis,
                'improvement': f"Added {min_emojis - current_emojis} emojis for better engagement"
            }
        
        return {'changed': False, 'text': text}
    
    def _optimize_cta(self, text: str, platform: SocialPlatform) -> Dict:
        """ä¼˜åŒ–è¡ŒåŠ¨å·å¬ï¼ˆCTAï¼‰"""
        cta_patterns = [
            r'follow\s*(for|us)?',
            r'like\s*(and|&)?\s*subscribe',
            r'comment\s*below',
            r'share\s*(this)?'
        ]
        
        has_cta = any(re.search(pattern, text.lower()) for pattern in cta_patterns)
        
        if not has_cta:
            platform_ctas = {
                SocialPlatform.TIKTOK: "\n\nğŸ‘‰ Follow for more!",
                SocialPlatform.INSTAGRAM: "\n\nğŸ’¬ Drop a comment!",
                SocialPlatform.YOUTUBE: "\n\nğŸ‘ Like & Subscribe!"
            }
            
            cta = platform_ctas.get(platform, "\n\nğŸ’¡ Follow for more tips!")
            
            return {
                'changed': True,
                'text': text + cta,
                'improvement': "Added engaging call-to-action"
            }
        
        return {'changed': False, 'text': text}
    
    def _integrate_trending_keywords(self, text: str) -> Dict:
        """èå…¥è¶‹åŠ¿å…³é”®è¯"""
        # ç®€åŒ–å®ç° - å®é™…åº”è¯¥è¿æ¥è¶‹åŠ¿API
        trending = ['viral', '2024', 'musthave', 'gamechanger']
        
        text_lower = text.lower()
        integrated_any = False
        
        for keyword in trending:
            if keyword not in text_lower:
                # æ™ºèƒ½èå…¥å…³é”®è¯
                text = text.replace('product', f'{keyword} product', 1)
                integrated_any = True
                break
        
        if integrated_any:
            return {
                'changed': True,
                'text': text,
                'improvement': "Integrated trending keywords"
            }
        
        return {'changed': False, 'text': text}
    
    def _analyze_sentiment(self, text: str) -> Dict:
        """åˆ†ææ–‡æœ¬æƒ…æ„Ÿ"""
        try:
            result = self.sentiment_analyzer(text)[0]
            return {
                'label': result['label'],
                'score': result['score'],
                'positive': result['label'] == 'POSITIVE'
            }
        except:
            return {'label': 'NEUTRAL', 'score': 0.5, 'positive': True}
    
    def _load_trending_keywords(self) -> List[str]:
        """åŠ è½½è¶‹åŠ¿å…³é”®è¯ï¼ˆå®é™…åº”è¿æ¥è¶‹åŠ¿APIï¼‰"""
        return [
            'viral', 'trending', '2024', 'musthave', 'fyp',
            'foryou', 'explore', 'reels', 'shorts', 'mustwatch'
        ]


class HashtagOptimizer:
    """æ ‡ç­¾ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.platform_limits = {
            SocialPlatform.TIKTOK: 100,  # å­—ç¬¦æ•°é™åˆ¶
            SocialPlatform.INSTAGRAM: 30,  # æ ‡ç­¾æ•°é‡é™åˆ¶
            SocialPlatform.YOUTUBE: 15,   # å»ºè®®æ•°é‡
            SocialPlatform.TWITTER: 2     # å»ºè®®æ•°é‡
        }
        
    def optimize_hashtags(self, content: str, platform: SocialPlatform, 
                         category: str = None) -> Dict:
        """ä¼˜åŒ–æ ‡ç­¾ç­–ç•¥"""
        
        # æå–ç°æœ‰æ ‡ç­¾
        existing_tags = self._extract_hashtags(content)
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        recommendations = {
            'keep': [],      # ä¿ç•™çš„æ ‡ç­¾
            'remove': [],    # å»ºè®®ç§»é™¤çš„æ ‡ç­¾
            'add': [],       # å»ºè®®æ·»åŠ çš„æ ‡ç­¾
            'strategy': {}   # æ ‡ç­¾ç­–ç•¥
        }
        
        # 1. åˆ†æç°æœ‰æ ‡ç­¾
        for tag in existing_tags:
            tag_quality = self._analyze_hashtag_quality(tag, platform)
            if tag_quality['score'] >= 0.7:
                recommendations['keep'].append({
                    'tag': tag,
                    'reason': tag_quality['reason'],
                    'score': tag_quality['score']
                })
            else:
                recommendations['remove'].append({
                    'tag': tag,
                    'reason': tag_quality['reason'],
                    'score': tag_quality['score']
                })
        
        # 2. æ¨èæ–°æ ‡ç­¾
        suggested_tags = self._suggest_hashtags(content, platform, category)
        recommendations['add'] = suggested_tags
        
        # 3. åˆ¶å®šæ ‡ç­¾ç­–ç•¥
        recommendations['strategy'] = self._create_hashtag_strategy(
            platform, len(recommendations['keep']), len(recommendations['add'])
        )
        
        # 4. ç”Ÿæˆæœ€ç»ˆæ ‡ç­¾é›†
        final_tags = self._compile_final_hashtags(recommendations, platform)
        
        return {
            'original_tags': existing_tags,
            'optimized_tags': final_tags,
            'recommendations': recommendations,
            'estimated_reach': self._estimate_reach(final_tags)
        }
    
    def _extract_hashtags(self, text: str) -> List[str]:
        """æå–æ–‡æœ¬ä¸­çš„æ ‡ç­¾"""
        return re.findall(r'#\w+', text)
    
    def _analyze_hashtag_quality(self, tag: str, platform: SocialPlatform) -> Dict:
        """åˆ†ææ ‡ç­¾è´¨é‡"""
        score = 1.0
        reasons = []
        
        # é•¿åº¦æ£€æŸ¥
        if len(tag) > 20:
            score *= 0.7
            reasons.append("Too long")
        elif len(tag) < 3:
            score *= 0.5
            reasons.append("Too short")
        
        # ç‰¹æ®Šå­—ç¬¦æ£€æŸ¥
        if re.search(r'[^\w#]', tag):
            score *= 0.3
            reasons.append("Contains special characters")
        
        # å¹³å°ç‰¹å®šè§„åˆ™
        if platform == SocialPlatform.TIKTOK:
            if tag.lower() in ['#fyp', '#foryou', '#foryoupage']:
                score *= 1.2
                reasons.append("High visibility tag")
        
        # åƒåœ¾æ ‡ç­¾æ£€æŸ¥
        spam_patterns = ['#follow4follow', '#f4f', '#like4like']
        if any(pattern in tag.lower() for pattern in spam_patterns):
            score *= 0.1
            reasons.append("Spam tag")
        
        return {
            'score': min(score, 1.0),
            'reason': ', '.join(reasons) if reasons else 'Good quality'
        }
    
    def _suggest_hashtags(self, content: str, platform: SocialPlatform, 
                         category: str = None) -> List[Dict]:
        """å»ºè®®ç›¸å…³æ ‡ç­¾"""
        suggestions = []
        
        # åŸºç¡€æ ‡ç­¾æ± ï¼ˆå®é™…åº”è¯¥ä»æ•°æ®åº“è·å–ï¼‰
        tag_pools = {
            'general': ['#eufy', '#smarthome', '#security', '#tech', '#innovation'],
            'product': ['#homesecurity', '#smartcamera', '#wirelesscamera', '#securitysystem'],
            'trending': ['#2024tech', '#musthave', '#hometech', '#safetyfirst'],
            'platform_specific': {
                SocialPlatform.TIKTOK: ['#fyp', '#foryoupage', '#tiktokmademebuyit'],
                SocialPlatform.INSTAGRAM: ['#reels', '#explore', '#instahome'],
                SocialPlatform.YOUTUBE: ['#shorts', '#youtubeshorts', '#tech']
            }
        }
        
        # 1. æ·»åŠ å“ç‰Œæ ‡ç­¾
        suggestions.extend([
            {'tag': '#eufy', 'type': 'brand', 'priority': 1.0},
            {'tag': '#eufysecurity', 'type': 'brand', 'priority': 0.9}
        ])
        
        # 2. æ·»åŠ ç±»åˆ«æ ‡ç­¾
        if category:
            category_tags = tag_pools.get('product', [])
            for tag in category_tags[:3]:
                suggestions.append({
                    'tag': tag,
                    'type': 'category',
                    'priority': 0.8
                })
        
        # 3. æ·»åŠ å¹³å°ç‰¹å®šæ ‡ç­¾
        platform_tags = tag_pools.get('platform_specific', {}).get(platform, [])
        for tag in platform_tags[:2]:
            suggestions.append({
                'tag': tag,
                'type': 'platform',
                'priority': 0.9
            })
        
        # 4. æ·»åŠ è¶‹åŠ¿æ ‡ç­¾
        trending_tags = tag_pools.get('trending', [])
        for tag in trending_tags[:2]:
            suggestions.append({
                'tag': tag,
                'type': 'trending',
                'priority': 0.7
            })
        
        return sorted(suggestions, key=lambda x: x['priority'], reverse=True)
    
    def _create_hashtag_strategy(self, platform: SocialPlatform, 
                                existing_count: int, suggested_count: int) -> Dict:
        """åˆ›å»ºæ ‡ç­¾ç­–ç•¥"""
        strategy = {
            'total_recommended': 0,
            'distribution': {},
            'placement': '',
            'tips': []
        }
        
        if platform == SocialPlatform.TIKTOK:
            strategy['total_recommended'] = 3-5
            strategy['distribution'] = {
                'brand': 1,
                'niche': 2,
                'trending': 1,
                'broad': 1
            }
            strategy['placement'] = 'In caption or first comment'
            strategy['tips'] = [
                'Mix niche and broad hashtags',
                'Use trending sounds with relevant hashtags',
                'Avoid banned or shadowbanned tags'
            ]
        
        elif platform == SocialPlatform.INSTAGRAM:
            strategy['total_recommended'] = 10-15
            strategy['distribution'] = {
                'brand': 2,
                'niche': 5,
                'medium': 5,
                'broad': 3
            }
            strategy['placement'] = 'First comment for cleaner caption'
            strategy['tips'] = [
                'Use mix of popularity levels',
                'Hide hashtags in first comment',
                'Create branded hashtag campaigns'
            ]
        
        return strategy
    
    def _compile_final_hashtags(self, recommendations: Dict, 
                               platform: SocialPlatform) -> List[str]:
        """ç¼–è¯‘æœ€ç»ˆæ ‡ç­¾é›†"""
        final_tags = []
        
        # æ·»åŠ ä¿ç•™çš„æ ‡ç­¾
        final_tags.extend([item['tag'] for item in recommendations['keep']])
        
        # æ·»åŠ æ¨èçš„æ ‡ç­¾
        limit = self.platform_limits.get(platform, 10)
        remaining_slots = limit - len(final_tags)
        
        for item in recommendations['add'][:remaining_slots]:
            if isinstance(item, dict):
                final_tags.append(item['tag'])
            else:
                final_tags.append(item)
        
        return final_tags
    
    def _estimate_reach(self, hashtags: List[str]) -> int:
        """ä¼°ç®—æ ‡ç­¾è¦†ç›–èŒƒå›´"""
        # ç®€åŒ–å®ç° - å®é™…åº”æŸ¥è¯¢æ ‡ç­¾ä½¿ç”¨æ•°æ®
        base_reach = 10000
        
        for tag in hashtags:
            if tag.lower() in ['#fyp', '#foryou', '#trending']:
                base_reach *= 5
            elif tag.lower() in ['#eufy', '#smarthome']:
                base_reach *= 2
            else:
                base_reach *= 1.2
        
        return int(min(base_reach, 10000000))  # ä¸Šé™1000ä¸‡


class TimingOptimizer:
    """å‘å¸ƒæ—¶æœºä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.platform_peaks = {
            SocialPlatform.TIKTOK: {
                'weekday': [(6, 10), (19, 23)],
                'weekend': [(9, 11), (19, 23)]
            },
            SocialPlatform.INSTAGRAM: {
                'weekday': [(7, 9), (12, 13), (17, 19)],
                'weekend': [(11, 13), (19, 21)]
            },
            SocialPlatform.YOUTUBE: {
                'weekday': [(12, 15), (19, 22)],
                'weekend': [(9, 11), (14, 16), (19, 22)]
            }
        }
    
    def get_optimal_posting_times(self, platform: SocialPlatform, 
                                 target_timezone: str = 'UTC') -> Dict:
        """è·å–æœ€ä½³å‘å¸ƒæ—¶é—´"""
        current_time = datetime.now()
        day_type = 'weekend' if current_time.weekday() >= 5 else 'weekday'
        
        recommendations = {
            'immediate': self._should_post_now(platform, current_time),
            'next_optimal_slots': [],
            'weekly_schedule': {},
            'timezone_considerations': []
        }
        
        # è·å–å¹³å°é«˜å³°æ—¶æ®µ
        peak_times = self.platform_peaks.get(platform, {}).get(day_type, [])
        
        # è®¡ç®—ä¸‹ä¸€ä¸ªæœ€ä½³æ—¶æ®µ
        for start_hour, end_hour in peak_times:
            for hour in range(start_hour, end_hour):
                next_slot = current_time.replace(hour=hour, minute=0, second=0)
                if next_slot > current_time:
                    recommendations['next_optimal_slots'].append({
                        'time': next_slot.isoformat(),
                        'quality': 'peak',
                        'expected_reach_multiplier': 2.5
                    })
        
        # ç”Ÿæˆä¸€å‘¨å‘å¸ƒè®¡åˆ’
        recommendations['weekly_schedule'] = self._generate_weekly_schedule(platform)
        
        # æ—¶åŒºè€ƒè™‘
        recommendations['timezone_considerations'] = [
            {'timezone': 'EST', 'offset': -5, 'audience_percentage': 0.3},
            {'timezone': 'PST', 'offset': -8, 'audience_percentage': 0.25},
            {'timezone': 'CST', 'offset': -6, 'audience_percentage': 0.2}
        ]
        
        return recommendations
    
    def _should_post_now(self, platform: SocialPlatform, current_time: datetime) -> Dict:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç«‹å³å‘å¸ƒ"""
        hour = current_time.hour
        day_type = 'weekend' if current_time.weekday() >= 5 else 'weekday'
        peak_times = self.platform_peaks.get(platform, {}).get(day_type, [])
        
        is_peak = any(start <= hour < end for start, end in peak_times)
        
        return {
            'recommended': is_peak,
            'reason': 'Peak engagement hours' if is_peak else 'Off-peak hours',
            'engagement_modifier': 1.5 if is_peak else 0.8
        }
    
    def _generate_weekly_schedule(self, platform: SocialPlatform) -> Dict:
        """ç”Ÿæˆä¸€å‘¨å‘å¸ƒè®¡åˆ’"""
        schedule = {}
        days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        
        for i, day in enumerate(days):
            day_type = 'weekend' if i >= 5 else 'weekday'
            peak_times = self.platform_peaks.get(platform, {}).get(day_type, [])
            
            schedule[day] = {
                'optimal_times': [f"{start}:00-{end}:00" for start, end in peak_times],
                'posts_per_day': 2 if platform == SocialPlatform.TIKTOK else 1,
                'content_type_suggestion': self._get_content_suggestion(day, platform)
            }
        
        return schedule
    
    def _get_content_suggestion(self, day: str, platform: SocialPlatform) -> str:
        """è·å–å†…å®¹ç±»å‹å»ºè®®"""
        suggestions = {
            'Monday': 'Motivational/Educational content',
            'Tuesday': 'Tips and tutorials',
            'Wednesday': 'Behind-the-scenes',
            'Thursday': 'Throwback/User testimonials',
            'Friday': 'Fun/Entertainment content',
            'Saturday': 'Lifestyle/Aspirational content',
            'Sunday': 'Planning/Preparation content'
        }
        
        return suggestions.get(day, 'General content')


class SocialContentAIOptimizer:
    """ç¤¾äº¤å†…å®¹AIä¼˜åŒ–å™¨ä¸»ç±»"""
    
    def __init__(self):
        self.video_analyzer = VideoAnalyzer()
        self.audio_analyzer = AudioAnalyzer()
        self.text_optimizer = TextOptimizer()
        self.hashtag_optimizer = HashtagOptimizer()
        self.timing_optimizer = TimingOptimizer()
        
        # å¹³å°ç‰¹å®šåˆ†æå™¨
        self.platform_analyzers = {
            SocialPlatform.TIKTOK: TikTokAIAnalyzer(),
            SocialPlatform.INSTAGRAM: InstagramAIAnalyzer(),
            SocialPlatform.YOUTUBE: YouTubeAIAnalyzer()
        }
    
    def optimize_for_ai_recommendation(self, content: Dict, 
                                     platform: SocialPlatform) -> SocialOptimizationResult:
        """ä¼˜åŒ–å†…å®¹ä»¥è·å¾—AIæ¨è"""
        
        # æ£€æµ‹å†…å®¹ç±»å‹
        content_type = self._detect_content_type(content)
        
        # è·å–å¹³å°åˆ†æå™¨
        analyzer = self.platform_analyzers.get(platform)
        if not analyzer:
            raise ValueError(f"Unsupported platform: {platform}")
        
        # åˆå§‹åŒ–ä¼˜åŒ–ç»“æœ
        optimization_result = SocialOptimizationResult(
            platform=platform,
            content_type=content_type,
            original_content=content,
            optimized_content={},
            ai_recommendation_score=0.0,
            first_3_seconds_score=0.0,
            completion_rate_prediction=0.0,
            engagement_prediction=0.0,
            viral_potential_score=0.0,
            optimization_suggestions=[],
            metadata_enhancements={},
            hashtag_recommendations=[],
            timing_recommendations={}
        )
        
        # 1. è§†é¢‘å†…å®¹ä¼˜åŒ–ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
        if content_type in [ContentType.VIDEO_SHORT, ContentType.VIDEO_LONG, ContentType.REEL]:
            video_optimization = self._optimize_video_content(content, platform, analyzer)
            optimization_result.first_3_seconds_score = video_optimization['first_3_seconds_score']
            optimization_result.completion_rate_prediction = video_optimization['completion_rate']
            optimization_result.optimization_suggestions.extend(video_optimization['suggestions'])
        
        # 2. æ–‡æœ¬å†…å®¹ä¼˜åŒ–
        if content.get('caption'):
            text_optimization = self.text_optimizer.optimize_caption(
                content['caption'], 
                platform
            )
            optimization_result.optimized_content['caption'] = text_optimization['optimized']
            optimization_result.optimization_suggestions.extend([
                {'type': 'caption', 'improvement': imp} 
                for imp in text_optimization['improvements']
            ])
        
        # 3. æ ‡ç­¾ä¼˜åŒ–
        hashtag_optimization = self.hashtag_optimizer.optimize_hashtags(
            content.get('caption', '') + ' ' + ' '.join(content.get('hashtags', [])),
            platform,
            content.get('category')
        )
        optimization_result.hashtag_recommendations = hashtag_optimization['optimized_tags']
        optimization_result.metadata_enhancements['hashtag_strategy'] = hashtag_optimization['recommendations']['strategy']
        
        # 4. å‘å¸ƒæ—¶æœºä¼˜åŒ–
        timing_recommendations = self.timing_optimizer.get_optimal_posting_times(platform)
        optimization_result.timing_recommendations = timing_recommendations
        
        # 5. è®¡ç®—ç»¼åˆAIæ¨èåˆ†æ•°
        optimization_result.ai_recommendation_score = self._calculate_ai_recommendation_score(
            optimization_result, analyzer
        )
        
        # 6. é¢„æµ‹äº’åŠ¨ç‡
        optimization_result.engagement_prediction = self._predict_engagement_rate(
            optimization_result, platform
        )
        
        # 7. è®¡ç®—ç—…æ¯’ä¼ æ’­æ½œåŠ›
        optimization_result.viral_potential_score = self._calculate_viral_potential(
            optimization_result
        )
        
        return optimization_result
    
    def _detect_content_type(self, content: Dict) -> ContentType:
        """æ£€æµ‹å†…å®¹ç±»å‹"""
        if content.get('video_path'):
            # æ£€æŸ¥è§†é¢‘æ—¶é•¿
            cap = cv2.VideoCapture(content['video_path'])
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
            duration = frame_count / fps if fps > 0 else 0
            cap.release()
            
            if duration < 60:
                return ContentType.VIDEO_SHORT
            else:
                return ContentType.VIDEO_LONG
        
        elif content.get('images'):
            if len(content['images']) > 1:
                return ContentType.CAROUSEL
            else:
                return ContentType.IMAGE_POST
        
        elif content.get('is_story'):
            return ContentType.STORY
        
        return ContentType.IMAGE_POST
    
    def _optimize_video_content(self, content: Dict, platform: SocialPlatform, 
                               analyzer) -> Dict:
        """ä¼˜åŒ–è§†é¢‘å†…å®¹"""
        video_path = content.get('video_path')
        if not video_path:
            return {
                'first_3_seconds_score': 0,
                'completion_rate': 0,
                'suggestions': []
            }
        
        # åˆ†æå‰3ç§’
        first_3_metrics = self.video_analyzer.analyze_first_3_seconds(video_path)
        
        # åˆ†æéŸ³é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
        audio_metrics = {}
        if content.get('audio_path'):
            audio_metrics = self.audio_analyzer.analyze_audio_hooks(content['audio_path'])
        
        # å¹³å°ç‰¹å®šä¼˜åŒ–
        platform_optimization = analyzer.optimize_opening(
            video_path,
            target_retention_rate=0.85
        )
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        suggestions = []
        
        if first_3_metrics['hook_strength'] < 0.7:
            suggestions.append({
                'priority': 'high',
                'category': 'hook',
                'suggestion': 'Strengthen opening hook - add motion, face, or scene change',
                'impact': 'Can improve retention by 20-30%'
            })
        
        if first_3_metrics['face_presence'] < 0.5:
            suggestions.append({
                'priority': 'medium',
                'category': 'human_element',
                'suggestion': 'Add human face in first 3 seconds for better connection',
                'impact': 'Increases engagement by 15-20%'
            })
        
        if audio_metrics.get('trending_audio_match', 0) < 0.5:
            suggestions.append({
                'priority': 'medium',
                'category': 'audio',
                'suggestion': 'Use trending audio for better discoverability',
                'impact': 'Can increase reach by 50-100%'
            })
        
        # é¢„æµ‹å®Œæ’­ç‡
        completion_rate = self._predict_completion_rate(
            first_3_metrics, 
            audio_metrics,
            platform
        )
        
        return {
            'first_3_seconds_score': first_3_metrics['hook_strength'],
            'completion_rate': completion_rate,
            'suggestions': suggestions,
            'detailed_metrics': {
                'video': first_3_metrics,
                'audio': audio_metrics
            }
        }
    
    def _predict_completion_rate(self, video_metrics: Dict, audio_metrics: Dict, 
                                platform: SocialPlatform) -> float:
        """é¢„æµ‹è§†é¢‘å®Œæ’­ç‡"""
        # åŸºç¡€å®Œæ’­ç‡
        base_rate = 0.3
        
        # è§†é¢‘å› ç´ å½±å“
        video_multiplier = 1.0
        video_multiplier *= (1 + video_metrics.get('hook_strength', 0) * 0.5)
        video_multiplier *= (1 + video_metrics.get('face_presence', 0) * 0.2)
        video_multiplier *= (1 + min(video_metrics.get('scene_changes', 0) / 3, 1) * 0.1)
        
        # éŸ³é¢‘å› ç´ å½±å“
        audio_multiplier = 1.0
        if audio_metrics:
            audio_multiplier *= (1 + audio_metrics.get('beat_strength', 0) * 0.2)
            audio_multiplier *= (1 + audio_metrics.get('trending_audio_match', 0) * 0.3)
        
        # å¹³å°ç‰¹å®šè°ƒæ•´
        platform_multipliers = {
            SocialPlatform.TIKTOK: 1.2,    # TikTokç”¨æˆ·å®Œæ’­ç‡è¾ƒé«˜
            SocialPlatform.INSTAGRAM: 0.9,   # Reelså®Œæ’­ç‡ä¸­ç­‰
            SocialPlatform.YOUTUBE: 0.7      # Shortså®Œæ’­ç‡è¾ƒä½
        }
        
        platform_multiplier = platform_multipliers.get(platform, 1.0)
        
        # è®¡ç®—æœ€ç»ˆå®Œæ’­ç‡
        predicted_rate = base_rate * video_multiplier * audio_multiplier * platform_multiplier
        
        return min(predicted_rate, 0.95)  # ä¸Šé™95%
    
    def _calculate_ai_recommendation_score(self, result: SocialOptimizationResult, 
                                         analyzer) -> float:
        """è®¡ç®—AIæ¨èæ¦‚ç‡å¾—åˆ†"""
        score_components = {
            'content_quality': 0.0,
            'engagement_signals': 0.0,
            'platform_alignment': 0.0,
            'timing_optimization': 0.0,
            'metadata_quality': 0.0
        }
        
        # 1. å†…å®¹è´¨é‡åˆ†æ•°
        if result.content_type in [ContentType.VIDEO_SHORT, ContentType.REEL]:
            score_components['content_quality'] = (
                result.first_3_seconds_score * 0.6 +
                result.completion_rate_prediction * 0.4
            )
        else:
            score_components['content_quality'] = 0.7  # é»˜è®¤å€¼
        
        # 2. äº’åŠ¨ä¿¡å·åˆ†æ•°
        caption_sentiment = result.optimized_content.get('caption_sentiment', {})
        if caption_sentiment.get('positive', False):
            score_components['engagement_signals'] += 0.3
        
        # æ ‡ç­¾è´¨é‡
        if len(result.hashtag_recommendations) > 0:
            score_components['engagement_signals'] += 0.4
        
        # 3. å¹³å°å¥‘åˆåº¦
        score_components['platform_alignment'] = analyzer.calculate_platform_fit_score(result)
        
        # 4. æ—¶æœºä¼˜åŒ–åˆ†æ•°
        if result.timing_recommendations.get('immediate', {}).get('recommended', False):
            score_components['timing_optimization'] = 0.8
        else:
            score_components['timing_optimization'] = 0.5
        
        # 5. å…ƒæ•°æ®è´¨é‡
        if result.metadata_enhancements:
            score_components['metadata_quality'] = 0.7
        
        # è®¡ç®—åŠ æƒæ€»åˆ†
        weights = {
            'content_quality': 0.4,
            'engagement_signals': 0.2,
            'platform_alignment': 0.2,
            'timing_optimization': 0.1,
            'metadata_quality': 0.1
        }
        
        total_score = sum(
            score_components[component] * weights[component] 
            for component in score_components
        )
        
        return round(total_score, 2)
    
    def _predict_engagement_rate(self, result: SocialOptimizationResult, 
                                platform: SocialPlatform) -> float:
        """é¢„æµ‹å†…å®¹äº’åŠ¨ç‡"""
        # åŸºç¡€äº’åŠ¨ç‡ï¼ˆæ ¹æ®å¹³å°å¹³å‡å€¼ï¼‰
        base_engagement = {
            SocialPlatform.TIKTOK: 0.05,     # 5%
            SocialPlatform.INSTAGRAM: 0.03,    # 3%
            SocialPlatform.YOUTUBE: 0.04      # 4%
        }
        
        base_rate = base_engagement.get(platform, 0.03)
        
        # æ ¹æ®ä¼˜åŒ–å› ç´ è°ƒæ•´
        multiplier = 1.0
        
        # AIæ¨èåˆ†æ•°å½±å“
        multiplier *= (1 + result.ai_recommendation_score * 0.5)
        
        # å†…å®¹è´¨é‡å½±å“
        if result.first_3_seconds_score > 0.8:
            multiplier *= 1.3
        
        # æ ‡ç­¾ä¼˜åŒ–å½±å“
        if len(result.hashtag_recommendations) >= 5:
            multiplier *= 1.2
        
        # å‘å¸ƒæ—¶æœºå½±å“
        if result.timing_recommendations.get('immediate', {}).get('recommended', False):
            multiplier *= 1.1
        
        predicted_engagement = base_rate * multiplier
        
        return round(min(predicted_engagement, 0.25), 3)  # ä¸Šé™25%
    
    def _calculate_viral_potential(self, result: SocialOptimizationResult) -> float:
        """è®¡ç®—ç—…æ¯’ä¼ æ’­æ½œåŠ›åˆ†æ•°"""
        viral_factors = {
            'ai_recommendation': result.ai_recommendation_score,
            'completion_rate': result.completion_rate_prediction,
            'engagement_prediction': result.engagement_prediction,
            'content_uniqueness': 0.7,  # é»˜è®¤å€¼ï¼Œå®é™…åº”é€šè¿‡å†…å®¹åˆ†æå¾—å‡º
            'timing_quality': 0.8 if result.timing_recommendations.get('immediate', {}).get('recommended') else 0.5,
            'hashtag_reach': min(len(result.hashtag_recommendations) / 10, 1.0)
        }
        
        # æƒé‡åˆ†é…
        weights = {
            'ai_recommendation': 0.3,
            'completion_rate': 0.25,
            'engagement_prediction': 0.2,
            'content_uniqueness': 0.15,
            'timing_quality': 0.05,
            'hashtag_reach': 0.05
        }
        
        viral_score = sum(
            viral_factors[factor] * weights[factor] 
            for factor in viral_factors
        )
        
        # ç—…æ¯’ä¼ æ’­éœ€è¦å¤šä¸ªå› ç´ éƒ½è¡¨ç°è‰¯å¥½
        if viral_score > 0.7 and result.ai_recommendation_score > 0.8:
            viral_score *= 1.2  # é¢å¤–åŠ æˆ
        
        return round(min(viral_score, 1.0), 2)


class TikTokAIAnalyzer:
    """TikTokå¹³å°AIåˆ†æå™¨"""
    
    def optimize_opening(self, video_path: str, target_retention_rate: float) -> Dict:
        """ä¼˜åŒ–è§†é¢‘å¼€åœº"""
        return {
            'optimized': True,
            'retention_improvement': 0.15,
            'suggestions': [
                'Add text overlay in first second',
                'Start with action or movement',
                'Use pattern interrupt technique'
            ]
        }
    
    def generate_ai_friendly_captions(self, content: Dict, 
                                    include_keywords: bool = True,
                                    semantic_enhancement: bool = True) -> str:
        """ç”ŸæˆAIå‹å¥½çš„å­—å¹•"""
        base_caption = content.get('caption', '')
        
        if include_keywords:
            # æ·»åŠ å…³é”®è¯
            base_caption += " #eufy #smarthome"
        
        if semantic_enhancement:
            # è¯­ä¹‰å¢å¼º
            base_caption = base_caption.replace('camera', 'smart security camera')
            base_caption = base_caption.replace('buy', 'get yours')
        
        return base_caption
    
    def suggest_ai_friendly_hashtags(self, content: Dict) -> List[str]:
        """å»ºè®®AIå‹å¥½çš„æ ‡ç­¾"""
        return ['#fyp', '#foryoupage', '#eufy', '#smarthome', '#securitycamera']
    
    def craft_ai_optimized_description(self, content: Dict) -> str:
        """åˆ›å»ºAIä¼˜åŒ–çš„æè¿°"""
        return f"Discover how {content.get('product_name', 'Eufy')} can transform your home security! ğŸ âœ¨"
    
    def determine_category_signals(self, content: Dict) -> List[str]:
        """ç¡®å®šç±»åˆ«ä¿¡å·"""
        return ['Technology', 'Home & Garden', 'Security']
    
    def predict_recommendation_probability(self, optimization_result: Dict) -> float:
        """é¢„æµ‹æ¨èæ¦‚ç‡"""
        base_prob = 0.5
        
        if optimization_result.get('first_3_seconds', {}).get('hook_strength', 0) > 0.7:
            base_prob += 0.2
        
        if optimization_result.get('metadata', {}).get('hashtags'):
            base_prob += 0.1
        
        return min(base_prob, 0.95)
    
    def calculate_platform_fit_score(self, result) -> float:
        """è®¡ç®—å¹³å°å¥‘åˆåº¦åˆ†æ•°"""
        return 0.85  # ç®€åŒ–å®ç°


class InstagramAIAnalyzer:
    """Instagramå¹³å°AIåˆ†æå™¨"""
    
    def optimize_opening(self, video_path: str, target_retention_rate: float) -> Dict:
        """ä¼˜åŒ–è§†é¢‘å¼€åœº"""
        return {
            'optimized': True,
            'retention_improvement': 0.12,
            'suggestions': [
                'Use aesthetic visuals',
                'Add smooth transitions',
                'Include lifestyle elements'
            ]
        }
    
    def generate_ai_friendly_captions(self, content: Dict, 
                                    include_keywords: bool = True,
                                    semantic_enhancement: bool = True) -> str:
        """ç”ŸæˆAIå‹å¥½çš„å­—å¹•"""
        return f"Transform your space with smart security ğŸ¡âœ¨ {content.get('caption', '')}"
    
    def suggest_ai_friendly_hashtags(self, content: Dict) -> List[str]:
        """å»ºè®®AIå‹å¥½çš„æ ‡ç­¾"""
        return ['#reels', '#explore', '#smarthome', '#homesecurity', '#modernliving']
    
    def craft_ai_optimized_description(self, content: Dict) -> str:
        """åˆ›å»ºAIä¼˜åŒ–çš„æè¿°"""
        return f"Smart home security that fits your lifestyle âœ¨ Shop link in bio!"
    
    def determine_category_signals(self, content: Dict) -> List[str]:
        """ç¡®å®šç±»åˆ«ä¿¡å·"""
        return ['Home Decor', 'Technology', 'Lifestyle']
    
    def predict_recommendation_probability(self, optimization_result: Dict) -> float:
        """é¢„æµ‹æ¨èæ¦‚ç‡"""
        return 0.7  # ç®€åŒ–å®ç°
    
    def calculate_platform_fit_score(self, result) -> float:
        """è®¡ç®—å¹³å°å¥‘åˆåº¦åˆ†æ•°"""
        return 0.8  # ç®€åŒ–å®ç°


class YouTubeAIAnalyzer:
    """YouTubeå¹³å°AIåˆ†æå™¨"""
    
    def optimize_opening(self, video_path: str, target_retention_rate: float) -> Dict:
        """ä¼˜åŒ–è§†é¢‘å¼€åœº"""
        return {
            'optimized': True,
            'retention_improvement': 0.1,
            'suggestions': [
                'Add compelling hook question',
                'Preview value proposition',
                'Use chapter markers'
            ]
        }
    
    def generate_ai_friendly_captions(self, content: Dict, 
                                    include_keywords: bool = True,
                                    semantic_enhancement: bool = True) -> str:
        """ç”ŸæˆAIå‹å¥½çš„å­—å¹•"""
        return f"{content.get('caption', '')} | Eufy Smart Security"
    
    def suggest_ai_friendly_hashtags(self, content: Dict) -> List[str]:
        """å»ºè®®AIå‹å¥½çš„æ ‡ç­¾"""
        return ['#shorts', '#smarthome', '#securitycamera', '#hometech', '#eufy']
    
    def craft_ai_optimized_description(self, content: Dict) -> str:
        """åˆ›å»ºAIä¼˜åŒ–çš„æè¿°"""
        return f"Quick look at {content.get('product_name', 'Eufy Security')} features!"
    
    def determine_category_signals(self, content: Dict) -> List[str]:
        """ç¡®å®šç±»åˆ«ä¿¡å·"""
        return ['Science & Technology', 'Howto & Style']
    
    def predict_recommendation_probability(self, optimization_result: Dict) -> float:
        """é¢„æµ‹æ¨èæ¦‚ç‡"""
        return 0.65  # ç®€åŒ–å®ç°
    
    def calculate_platform_fit_score(self, result) -> float:
        """è®¡ç®—å¹³å°å¥‘åˆåº¦åˆ†æ•°"""
        return 0.75  # ç®€åŒ–å®ç°


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºç”¨æ³•"""
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = SocialContentAIOptimizer()
    
    # ç¤ºä¾‹å†…å®¹
    sample_content = {
        'video_path': '/path/to/video.mp4',
        'audio_path': '/path/to/audio.mp3',
        'caption': 'Check out our new security camera!',
        'hashtags': ['#security', '#tech'],
        'category': 'home_security',
        'product_name': 'Eufy Security Camera S330'
    }
    
    # ä¸ºTikTokä¼˜åŒ–
    result = optimizer.optimize_for_ai_recommendation(
        sample_content, 
        SocialPlatform.TIKTOK
    )
    
    # è¾“å‡ºç»“æœ
    print("=== ç¤¾äº¤å†…å®¹AIä¼˜åŒ–ç»“æœ ===")
    print(f"å¹³å°: {result.platform.value}")
    print(f"å†…å®¹ç±»å‹: {result.content_type.value}")
    print(f"\nAIæ¨èå¾—åˆ†: {result.ai_recommendation_score}/1.0")
    print(f"é¦–3ç§’å¾—åˆ†: {result.first_3_seconds_score}/1.0")
    print(f"é¢„æµ‹å®Œæ’­ç‡: {result.completion_rate_prediction*100:.1f}%")
    print(f"é¢„æµ‹äº’åŠ¨ç‡: {result.engagement_prediction*100:.1f}%")
    print(f"ç—…æ¯’ä¼ æ’­æ½œåŠ›: {result.viral_potential_score}/1.0")
    
    print("\n=== ä¼˜åŒ–å»ºè®® ===")
    for i, suggestion in enumerate(result.optimization_suggestions[:5], 1):
        if isinstance(suggestion, dict):
            print(f"{i}. [{suggestion.get('priority', 'medium')}] {suggestion.get('suggestion', '')}")
            print(f"   å½±å“: {suggestion.get('impact', '')}")
        else:
            print(f"{i}. {suggestion}")
    
    print("\n=== æ¨èæ ‡ç­¾ ===")
    print(f"æ ‡ç­¾: {' '.join(result.hashtag_recommendations[:10])}")
    
    print("\n=== å‘å¸ƒæ—¶æœº ===")
    if result.timing_recommendations.get('immediate', {}).get('recommended'):
        print("å»ºè®®ç«‹å³å‘å¸ƒï¼(å½“å‰ä¸ºé«˜å³°æ—¶æ®µ)")
    else:
        next_slots = result.timing_recommendations.get('next_optimal_slots', [])
        if next_slots:
            print(f"ä¸‹ä¸€ä¸ªæœ€ä½³å‘å¸ƒæ—¶é—´: {next_slots[0]['time']}")


if __name__ == "__main__":
    # ä¸‹è½½å¿…è¦çš„æ•°æ®
    import nltk
    nltk.download('punkt', quiet=True)
    nltk.download('stopwords', quiet=True)
    
    main()